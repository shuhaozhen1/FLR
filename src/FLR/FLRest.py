import numpy as np
from scipy.integrate import quad

def flrdata(n: int, m: int, delta: int, beta_func):
    """
    Generates model form data Y = integral of beta(t) * X(t) dt + epsilon, where X(t) is random and given by X(t) = e * sin(t) with e being normal, beta is a given function, and epsilon is the random error.
    We have n realizations, and the data we collect are Y_i, (T_i1,...,T_im_i), X(T_i1), ...X(T_im), where time points T_ij are generated as in our previous chat.
    
    :param n: number of realizations of Y
    :param m: constant around which the number of observations for each realization is generated
    :param delta: range around m within which the number of observations for each realization is generated
    :param beta_func: function that takes a single argument t and returns the value of beta(t)
    :return: a tuple containing:
        - a numpy array of shape (n,) with the generated values of Y
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of T for each realization
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of X(T) for each realization
    """
    # Initialize the arrays to store the generated data for each realization
    Y = np.zeros(n)
    T = []
    X = []
    
    # Loop over each realization
    for i in range(n):
        # Generate the standard normal e for this realization
        e = np.random.normal()
        
        # Define X(t) for this realization as e * sin(t)
        x_func = lambda t: e * np.sin(t)
        
        # Generate the number of observations for this realization
        m_i = np.random.randint(m - delta, m + delta + 1)
        
        # Generate the time points at which to observe X(t)
        t = np.random.uniform(0, 1, size=m_i)
        
        # Calculate X(t) for this realization
        x = x_func(t)
        
        # Sort the time points and corresponding values of X in ascending order
        sorted_indices = np.argsort(t)
        t = t[sorted_indices]
        x = x[sorted_indices]
        
        # Define the integrand as the product of beta(t) and X(t)
        integrand = lambda t: beta_func(t) * x_func(t)
        
        # Calculate the integral of beta(t) * X(t) over the whole domain [0, 1]
        integral, _ = quad(integrand, 0, 1)
        
        # Generate the random error epsilon
        epsilon = 0.1 * np.random.normal()
        
        # Calculate Y for this realization
        y = integral + epsilon
        
        # Store the generated data for this realization
        Y[i] = y
        T.append(t)
        X.append(x)
    
    return Y, T, X

def loss(beta, data):
    """
    Calculates the loss for a given sequence of beta values using the model form data generated by the flrdata function.
    
    :param beta: numpy array of shape (k,) containing the sequence of beta values
    :param data: a tuple containing:
        - a numpy array of shape (n,) with the generated values of Y
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of T for each realization
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of X(T) for each realization
    :return: the calculated loss
    """
    # Unpack the data tuple into Y, T, and X
    Y, T, X = data
    
    # Check that the shapes of Y, T, and X are consistent
    assert Y.shape[0] == len(T) == len(X), "The shapes of Y, T, and X must be consistent"
    
    # Get the number of realizations and the length of the beta sequence
    n = Y.shape[0]
    k = beta.shape[0]
    
    # Initialize the variable to store the sum of squared errors
    sse = 0
    
    # Loop over each realization
    for i in range(n):
        # Get the time points and corresponding values of X for this realization
        t = T[i]
        x = X[i]
        
        # Initialize the variable to store the predicted value of Y for this realization
        y_pred = 0
        
        # Loop over each element in the beta sequence
        for j in range(k):
            # Calculate the time point i/k
            t_ik = (j + 1) / k
            
            # Find the index of the time point in T that is closest to i/k
            idx = np.argmin(np.abs(t - t_ik))
            
            # Get the corresponding value of X
            x_ik = x[idx]
            
            # Update the predicted value of Y for this realization
            y_pred += k**(-1) * beta[j] * x_ik
        
        # Update the sum of squared errors
        sse += (Y[i] - y_pred)**2
    
    # Calculate the loss as the mean squared error
    loss = sse / n
    
    return loss

from scipy.optimize import minimize

def find_best_beta(k: int, data):
    """
    Finds the sequence of length k that minimizes the loss function defined by the loss function.
    
    :param k: length of the beta sequence
    :param data: a tuple containing:
        - a numpy array of shape (n,) with the generated values of Y
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of T for each realization
        - a list of length n containing numpy arrays of shape (m[i],) with the generated values of X(T) for each realization
    :return: a numpy array of shape (k,) containing the sequence of beta values that minimizes the loss function
    """
    # Define a function to calculate the loss for a given sequence of beta values
    def f(beta):
        return loss(beta, data)
    
    # Initialize the beta sequence with zeros
    beta0 = np.zeros(k)
    
    # Find the sequence of beta values that minimizes the loss function
    res = minimize(f, beta0)
    
    # Return the optimal sequence of beta values
    return res.x


import numpy as np

# Define the length k of the beta sequence
k = 10

# Generate some model form data using our previous example code
n = 200
m = 20
delta = 2
beta_func = lambda t: np.sin(t)
data = flrdata(n, m, delta, beta_func)

# Find the optimal sequence of beta values using our new function
beta_opt = find_best_beta(k, data)

# Print the optimal sequence of beta values
print(f"Optimal sequence of beta values: {beta_opt}")
